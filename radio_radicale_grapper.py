import osimport sysimport urllibimport urlparse# http://docs.python-requests.org/en/latest/import requests# http://www.crummy.com/software/BeautifulSoup/bs4/doc/from bs4 import BeautifulSoup#from urllib.request import urlopenimport rebase_url='https://www.radioradicale.it/'def get_page(url):	html = requests.get(url).text	print html	return html	def get_chunks_file(url):	html = get_page(url)	p=re.findall('(http://audio\-aac\.radioradicale\.it:1935/aac\-1/_definst_/[0-9]{4}/[0-9]{2}/[0-9]{2}/.+\.m4a/)playlist\.m3u8',html)	tracker_base_url=p[0]	tracker_file_txt = get_page(tracker_base_url + 'playlist.m3u8')	tracker=re.findall('chunklist.*\.m3u8',tracker_file_txt)	chunks_url=tracker_base_url + tracker[0]	return chunks_urldef parse_udienze_list_page(page_num):	udienze_list={}	index=1	html=get_page('https://www.radioradicale.it/archivio?raggruppamenti_radio=6&field_data_1&field_data_2&page='+str(page_num))	udienze=re.findall('<a href="(/scheda/[0-9]+?/processo.+?)">(.+?)</a>',html)	for udienza in udienze:		chunks_url=get_chunks_file(base_url+udienza[0])		udienze_list.update({index: {'title': udienza[1], 'url': chunks_url}})		index += 1	return udienze_list			parse_udienze_list_page(0)print ('finito')